import os
import pickle
import numpy as np
import face_recognition
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from typing import Tuple, Optional, Any, Dict
import warnings
warnings.filterwarnings("ignore")

class FaceTrainer:
    def __init__(self):
        from config import Config
        self.config = Config
    
    def extract_embeddings(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
        
        Returns:
            tuple: (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏, –º–µ—Ç–∫–∏)
        """
        X: List[np.ndarray] = []  # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏
        y: List[int] = []  # –ú–µ—Ç–∫–∏
        
        print("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        for person_name in os.listdir(self.config.DATASET_DIR):
            person_path = os.path.join(self.config.DATASET_DIR, person_name)
            if not os.path.isdir(person_path):
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞
            if person_name == "Aleksander":
                label = 0
            elif person_name == "Egor":
                label = 1
            elif person_name == "Unknown":
                label = -1
            else:
                label = -1  # –î—Ä—É–≥–∏–µ –ø–∞–ø–∫–∏ —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏
            
            print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞: {person_name} (–∫–ª–∞—Å—Å {label})")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ
            processed = 0
            for file in os.listdir(person_path):
                if not file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                
                img_path = os.path.join(person_path, file)
                try:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∫–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image = face_recognition.load_image_file(img_path)
                    encodings = face_recognition.face_encodings(image)
                    
                    if encodings:
                        X.append(encodings[0])  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ª–∏—Ü–æ
                        y.append(label)
                        processed += 1
                    
                except Exception as e:
                    print(f"    ‚ùå –û—à–∏–±–∫–∞ {file}: {e}")
            
            print(f"    ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–æ—Ç–æ: {processed}")
        
        X_array = np.array(X)
        y_array = np.array(y)
        
        print(f"\nüìà –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(X_array)}")
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
        unique_labels = np.unique(y_array)
        for label in unique_labels:
            count = np.sum(y_array == label)
            name = self.config.LABELS.get(label, f"Class_{label}")
            print(f"  {name}: {count} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        with open(self.config.EMBEDDINGS_FILE, 'wb') as f:
            pickle.dump((X_array, y_array), f)
        
        print(f"üíæ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.config.EMBEDDINGS_FILE}")
        
        return X_array, y_array
    
    def train_classifier(self) -> Optional[SVC]:
        """
        –û–±—É—á–µ–Ω–∏–µ SVM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        
        Returns:
            SVC: –û–±—É—á–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        """
        print("üéì –û–±—É—á–µ–Ω–∏–µ SVM –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        if not os.path.exists(self.config.EMBEDDINGS_FILE):
            print("‚ùå –§–∞–π–ª —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        with open(self.config.EMBEDDINGS_FILE, 'rb') as f:
            X, y = pickle.load(f)
        
        if len(X) < 10:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return None
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"  –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_train)}")
        print(f"  –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_test)}")
        
        # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º SVM
        clf = SVC(
            kernel='linear',
            probability=True,
            class_weight='balanced'
        )
        
        clf.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        y_pred = clf.predict(X_test)
        accuracy = clf.score(X_test, y_test)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
        
        # –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
        target_names = [self.config.LABELS.get(i, f"Class_{i}") 
                       for i in np.unique(y)]
        report = classification_report(y_test, y_pred, 
                                      target_names=target_names)
        print(f"\n–û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:\n{report}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        with open(self.config.CLASSIFIER_FILE, 'wb') as f:
            pickle.dump(clf, f)
        
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {self.config.CLASSIFIER_FILE}")
        
        return clf
    
    def compute_centroids(self) -> Tuple[Optional[Dict[int, np.ndarray]], Optional[Dict[int, str]]]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        
        Returns:
            tuple: (—Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã, –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤)
        """
        print("üéØ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        if not os.path.exists(self.config.EMBEDDINGS_FILE):
            print("‚ùå –§–∞–π–ª —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None, None
        
        with open(self.config.EMBEDDINGS_FILE, 'rb') as f:
            X, y = pickle.load(f)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        centroids: Dict[int, np.ndarray] = {}
        label_names: Dict[int, str] = {}
        
        unique_labels = np.unique(y)
        for label in unique_labels:
            # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
            class_embeddings = X[y == label]
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥ (—Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
            centroid = class_embeddings.mean(axis=0)
            centroids[label] = centroid
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞
            name = self.config.LABELS.get(label, f"Class_{label}")
            label_names[label] = name
            
            print(f"  {name}: —Ü–µ–Ω—Ç—Ä–æ–∏–¥ –≤—ã—á–∏—Å–ª–µ–Ω ({len(class_embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã
        with open(self.config.CENTROIDS_FILE, 'wb') as f:
            pickle.dump((centroids, label_names), f)
        
        print(f"üíæ –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.config.CENTROIDS_FILE}")
        
        return centroids, label_names
    
    def train_full_model(self) -> bool:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ
        """
        print("=" * 50)
        print("–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –õ–ò–¶")
        print("=" * 50)
        
        try:
            # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            X, y = self.extract_embeddings()
            
            if len(X) == 0:
                print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False
            
            # 2. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤
            centroids, label_names = self.compute_centroids()
            
            if centroids is None:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã")
                return False
            
            # 3. –û–±—É—á–µ–Ω–∏–µ SVM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if len(np.unique(y)) >= 2:  # SVM –Ω—É–∂–Ω—ã –º–∏–Ω–∏–º—É–º 2 –∫–ª–∞—Å—Å–∞
                clf = self.train_classifier()
                if clf is None:
                    print("‚ö†Ô∏è  SVM –Ω–µ –æ–±—É—á–µ–Ω, –Ω–æ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥–æ—Ç–æ–≤—ã")
                else:
                    print("‚úÖ SVM —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω")
            
            print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
